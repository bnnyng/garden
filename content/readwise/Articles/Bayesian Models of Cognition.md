## New highlights added February 21, 2024 at 3:39 AM
- Our goal in this chapter is to illustrate the kinds of computational models of cognition that we can build if we assume that human learning and inference approximately follow the principles of Bayesian probabilistic inference, and to explain some of the mathematical ideas and techniques underlying those models. ([View Highlight](https://read.readwise.io/read/01hq2c4q6pcnr9b06hfbawdrrq))
- how does the human mind go beyond the data of experience? In other words, how does the mind build rich, abstract, veridical models of the world given only the sparse and noisy data that we observe through our senses? ([View Highlight](https://read.readwise.io/read/01hq2c52t0hmtb8a8yfc8qsfcc))
- It is a version of the classic problem of induction, which is as old as recorded Western thought and is the source of many deep problems and debates in modern philosophy of knowledge and philosophy of science. It is also at the heart of the difficulty in building machines with anything resembling human-like intelligence. ([View Highlight](https://read.readwise.io/read/01hq2c5ep65c3xtc0gk8nm3z00))
- Learning about causal relations, category structures, or the properties or names of objects are problems that are very close to the classic problems of induction that have been much discussed and puzzled over in the Western philosophical tradition. Showing how Bayesian methods can apply to these problems thus illustrates clearly their importance in understanding phenomena of induction more generally. ([View Highlight](https://read.readwise.io/read/01hq2c4asa69v5w13b8ar178na))
- Algorithmic or process accounts may be more satisfying in mechanistic terms, but they may also require assumptions about human processing mechanisms that are no longer needed when we assume that cognition is an approximately optimal response to the uncertainty and structure present in natural tasks and environments (Anderson, 1990). ([View Highlight](https://read.readwise.io/read/01hq2c76p9mqcqmv40tk2rbrcj))
- The history of computational models of cognition exhibits an enduring tension between models that emphasize symbolic representations and deductive inference, such as first order logic or phrase structure grammars, and models that emphasize continuous representations and statistical learning, such as connectionist networks or other associative systems ([View Highlight](https://read.readwise.io/read/01hq2czv8pzj84gzm6hhv50xkx))
    - Note: Probabilistic models bridge computationalist and connectionist (statistical) approaches to cognitive science.
- the most promising routes to understanding human intelligence in computational terms will involve deep interactions between these two traditionally opposing approaches, with sophisticated statistical inference machinery operating over structured symbolic knowledge representations. ([View Highlight](https://read.readwise.io/read/01hq2d074b12evpwf6tapst50j))
- The tension between symbols and statistics is perhaps only exceeded by the tension
  between accounts that focus on the importance of innate, domain-specific knowledge in explaining human cognition, and accounts that focus on domain-general learning mechanisms. Again, probabilistic models provide a middle ground where both approaches can productively meet, and they suggest various routes to resolving the tensions between these approaches by combining the important insights of both. ([View Highlight](https://read.readwise.io/read/01hq2d0n69whg262e687v4b7pf))
    - Note: Probabilistic models as a middle ground between innate knowledge and data.
- Crucially, these models do not require that the prior knowledge be innate. Bayesian inference in hierarchical probabilistic models can explain how abstract prior knowledge may itself be learned from data, and then put to use to guide learning in subsequent tasks and new environments. ([View Highlight](https://read.readwise.io/read/01hq2d345rxrthrrbx5p31429d))
- The key difference from Bayesian inference with finitely many hypotheses is that our beliefs about the hypotheses (both priors and posteriors) are now characterized by probability densities (notated by a lowercase “p”) rather than probabilities strictly speaking, and the sum over hypotheses becomes an integral. ([View Highlight](https://read.readwise.io/read/01hq4p6vynsfv6c23c2kr2h5z0))
    - Note: Advantage of Bayes over MLE.
- Collapsing this distribution down to a single number discards information, so Bayesians prefer to maintain distributions wherever possible (this attitude is similar to Marr’s (1982, p. 106) “principle of least commitment”) ([View Highlight](https://read.readwise.io/read/01hq4p8pvwvw6tj7thjtkrm15c))
    - Note: Now what is this?
- We can say that such a prior acts to “smooth” or “regularize” the observed data, damping out what might be misleading fluctuations when
  the data are far from the learner’s initial expectations. On a larger scale, these principles of Bayesian parameter estimation with informative “smoothing” priors have been applied to a number of cognitively interesting machine-learning problems, such as Bayesian learning in neural networks (Mackay, 2003). ([View Highlight](https://read.readwise.io/read/01hq4pdyk26x7sc59dn5j4q407))
    - Note: Weak priori have a smoothing effect!
- BAYESIANMODELS 11
  generating the observed data could take on one of several qualitatively different forms ([View Highlight](https://read.readwise.io/read/01hq4pgtfgb5mwh8h1g56ms30n))
    - Note: Need to parse this better.
- the Bayesian approach to model selection is a seamless application of the methods discussed so far. Hypotheses that differ in their complexity can be compared directly using Bayes’ rule, once they are reduced to probability distributions over the observable data (see Kass & Raftery, 1995). ([View Highlight](https://read.readwise.io/read/01hq4pkg9mxq1s6qzxmk8qygc3))
    - Note: Compared to weird frequentist hypothesis testing.
- a Bayesian learner judges the fit of a parameterized model not by how well it fits using the best parameter values, but by how well it fits using randomly selected parameters, where the parameters are drawn from a prior specified by the model (p(θ|h1) in Equation 16) (Ghahramani, 2004). This penalization of more complex models is known as the “Bayesian Occam’s razor” (Jeffreys & Berger, 1992; Mackay, 2003), and is illustrated in Figure 1b. ([View Highlight](https://read.readwise.io/read/01hq4pqem10q839arz2bj3k5k7))
- a probabilistic model simply defines the joint distribution for a system of random variables ([View Highlight](https://read.readwise.io/read/01hq4psj2q2ra3q07j54f5kra7))
- A graphical model associates a probability distribution with a graph. ([View Highlight](https://read.readwise.io/read/01hq4prx3dbnacyvtztc1qvzm1))
- If the edges indicate the direction of a dependency, the result is a directed graphical model. Our focus here will be on directed graphical models, which are also known as Bayesian networks or Bayes nets (Pearl, 1988). Bayesian networks can often be given a causal interpretation, where an edge between two nodes indicates that one node is a direct cause of the other, which makes them particularly appealing for modeling higher-level cognition. ([View Highlight](https://read.readwise.io/read/01hq4pyfyd88h6rpkjfx7p9dd4))
    - Note: Why causal?
- Markov condition: conditioned on its parents, each variable is independent of all other variables except its descendants (Pearl, 1988; Spirtes, Glymour, & Schienes, 1993). ([View Highlight](https://read.readwise.io/read/01hq4pzhr3ahck2j8reeka33me))
- This kind of model is commonly used in computational linguistics, where the xi might be the sequence of words in a document, and the zi the syntactic classes from which they are generated. ([View Highlight](https://read.readwise.io/read/01hq4q91nxk8cf402dywen5fht))
    - Note: Helpful example of latent model!
## New highlights added February 23, 2024 at 11:58 PM
- simple causal
  learning problem: given a candidate cause, C, and a candidate effect, E, people are asked to give a numerical rating assessing the degree to which C causes E.2 ([View Highlight](https://read.readwise.io/read/01hq94s77z22854f9d9y3y9vwt))
- The task of elemental causal induction can be seen as trying to infer which causal graphical model best characterizes the relationship between the variables C and E. ([View Highlight](https://read.readwise.io/read/01hq94taddbh2q19ewke6qdqa5))
- The problem of learning which causal graphical model is correct has two aspects: inferring the right causal structure, a problem of model selection, and determining the right parameters assuming a particular structure, a problem of parameter estimation. ([View Highlight](https://read.readwise.io/read/01hq94ts7v11j0mvk75m9k1zt0))
- This prior knowledge can be usefully described in terms of intuitive domain theories (Carey, 1985; Wellman & Gelman, 1992; Gopnik & Meltzoff, 1997), systems of abstract concepts and principles that specify the kinds of entities that can exist in a domain, their properties and possible states, and the kinds of causal relations that can exist between them. ([View Highlight](https://read.readwise.io/read/01hq94xyq409vb6h01hg6y65dd))
- It is often said that good statistical analyses should “let the data speak for themselves”, hence the motivation for maximum-likelihood estimation and other classical statistical methods that do not require a prior to be specified. Cognitive models, however, will usually aim for the opposite goal. Most human inferences are guided by background knowledge, and cognitive models should formalize this knowledge and show how it can be used for induction. ([View Highlight](https://read.readwise.io/read/01hq94ztrqv1s6mjn4jd2ytc97))
- In principle, however, we can develop hierarchical models with any number of levels — we can can continue adding hyperparameters and priors on these hyperparameters until we reach a level where we are willing to assume that the hyperparameters are fixed in advance. ([View Highlight](https://read.readwise.io/read/01hq955f2j03m5jnrzhpawkc2w))
- Yet these upper levels play a critical role — they allow knowledge to be shared across contexts that are related but distinct. ([View Highlight](https://read.readwise.io/read/01hq9557z0rm589jq9ftk0k9cc))
- Any hierarchical model, however, can be used for several different purposes. If α and β are fixed in advance, the model supports top-down learning: knowledge about α and β can guide inferences about the θi. If the θi are fixed in advance, the model supports bottom-up learning, and the θi can guide inferences about α and β. ([View Highlight](https://read.readwise.io/read/01hq95m07js4zxbmg6v7k5tyqk))
- The ability to support top-down and bottom-up inferences is a strength of the hierarchical approach, but simultaneous learning at multiple levels of abstraction is often required to account for human inferences. ([View Highlight](https://read.readwise.io/read/01hq95kq60en454cw0gsf6tdzt))
- The basic idea behind Monte Carlo methods is to represent a probability distribution
  by a set of samples from that distribution. Those samples provide an idea of which values have high probability (since high probability values are more likely to be produced as samples), and can be used in place of the distribution itself when performing various computations. ([View Highlight](https://read.readwise.io/read/01hq95rsd8kscftngcbvssn8cw))

# Bayesian Models of Conceptual Development: Learning as Building Models of the World

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article2.74d541386bbf.png)

# Metadata
- Author: [[Tomer D. Ullman and Joshua B. Tenenbaum]]
- Full Title: Bayesian Models of Conceptual Development: Learning as Building Models of the World

- URL: https://pdfs.semanticscholar.org/41b4/208497ea832b59a241708c3fe4b17973175d.pdf?_gl=1*1fny988*_ga*MTMxODU2MDc1LjE3MDg0MDAyNjI.*_ga_H7P4ZT52H5*MTcwODYzOTU0Ny42LjEuMTcwODYzOTcyNS4xNS4wLjA.

# Highlights
- The chief aim of computational approaches to cognitive development is to build models ofthis task and ofchildren’s minds as they solve it. ([View Highlight](https://read.readwise.io/read/01hq9ev300yahb1xnek1tgjxkt))
- The framework offers a precise but general formulation of the learning challenge: What does it mean to build a model of the world from experience, what is the logic by which this prob- lem can be solved, and what are the possible forms our models might take? ([View Highlight](https://read.readwise.io/read/01hq9ewaynf1cada7hk0pq1583))
- . A particular model m is framed in terms ofvariables describing the entities in a domain, relationships between these variables, and joint probability distributions over the values of these variables and others representing the observations that could constitute evidence for the model. ([View Highlight](https://read.readwise.io/read/01hq9ey2ze6hqaj0bmf2seg8rg))
- HBMs provide a general formalism for what must be built-in (the most abstract overhypotheses and primitives) and what can be learned (potentially, all lower-level constraints and hypotheses). ([View Highlight](https://read.readwise.io/read/01hq9f04r01wb6kyag1xt62hnf))
- Informally, we can think of a probabilistic program as simply a computer program that makes probabilistic choices. For a given input, there is no single deterministic output; rather, there is a probability distribution over outputs ([View Highlight](https://read.readwise.io/read/01hq9fdam3t4yewxqf13frqg10))
    - Note: Definition of probabilistic program, probabilistic GENERATIVE program. How seriously should we take the word "world" (c.f. skepticism around the term "world model")?
- A single run of the program samples values for each variable, generating one possible way the world could unfold—intuitively, imagining a possible world ([View Highlight](https://read.readwise.io/read/01hq9fdtzr7apyqndwzsn772k8))
- Probabilistic generative programs can be regarded as a modern incarnation of these ideas that combines abstract, structured causal knowledge with capacities for Bayesian inference and simulation-based reasoning over those models (Gerstenberg & Tenenbaum 2017). ([View Highlight](https://read.readwise.io/read/01hq9fg3h0jwhs73efa4wa9msw))
    - Note: Key insight: relationship between this method and representation learning.
- A generative program starts from positing the world that gives rise to perception. ([View Highlight](https://read.readwise.io/read/01hq9fmv1xm9c35796vt3218mk))
- As a probabilistic model, this generative program can be used for many purposes ([View Highlight](https://read.readwise.io/read/01hq9fn9psam83jmddmgqydecj))
    - Note: Prediction, inference, and generalization -- also the theme of "pragmatic statistics" talk from CUMMW. Note the difference between prediction and inference!
- Model building most generally is simply inference in a hierarchical probabilistic program—a program-generating program. ([View Highlight](https://read.readwise.io/read/01hq9fqnhg27sr84b7xjkennmv))
- Core knowledge refers to early-emerging, possibly innate expectations that infants have about the world. ([View Highlight](https://read.readwise.io/read/01hq9ftsgkt6f6z5vk2w0j8f0p))
    - Note: Spelke's work! Two key features: core knowledge is general and abstract over all entities in a domain; core knowledge is domain-specific.
- .We propose that core knowledge can be thought of as built-in, minimal, domain- specific libraries of generative programs. These programs implement the expectations of core knowledge through probabilistic simulation, which offers a different and valuable way to think about the form that core knowledge takes. ([View Highlight](https://read.readwise.io/read/01hq9fxn3370mepss7zphyakma))
- Conceptually, if“learning” is merely shifting around probability mass, then learning is not actually happening (Fodor 1998). ([View Highlight](https://read.readwise.io/read/01hq9grsrtx3qcbwzpm7mbdp3g))
- While one can think of the space of all possible programs that a child’s language of thought can express as existing in some sense, one should not think of that entire set as existing in the child’s head. Rather, the resource-rational child will hold in mind a lim- ited number ofhypotheses at a given moment—maybe only one (Vul et al. 2014), as if occupying a single point in conceptual space. She then applies program transformations to her models,moving her to new positions in that space. That the combination of programs and program transforma- tions theoretically expresses an infinite space does not mean the child doesn’t learn or discover something new, in the same way that a child’s ability to express and understand English does not mean that Shakespeare didn’t come up with something novel when he first wrote “O brave new world, that has such people in ’t!” ([View Highlight](https://read.readwise.io/read/01hq9gt44rr8xpvf3rqjzf6knn))
- Now, imagine that we tell the student to think of current as the flow of a fluid (Esposito 1969)—resistors inhibit the flow, voltage is the pressure, and so on. This does not make the original miniprogram any shorter or more predictive, and an ideal PLM could reject it. And yet, the student may find it helpful and meaningful, because she already has intuitive physics programs that can simulate and explain human-scale fluid behavior (Bates et al. 2019). ([View Highlight](https://read.readwise.io/read/01hq9gg30dkjccbtfa9s9bhf0c))
    - Note: Any analogous uses of this for learning mathematics?

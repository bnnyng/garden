---
ref-title: "Foundations of Intelligence in Natural and Artificial Systems: A Workshop Report"
ref-author: Santa Fe Institute
ref-publish-date: "2021"
ref-type: Workshop
ref-read-date: 2023-12-26
ref-link: https://arxiv.org/abs/2105.02198
aliases: 
tags:
  - raw
date: 2023-12-26
lastmod: 2023-12-29T14:52:50-08:00
---
# Highlights
- In 1988, Hans Moravec famously noted that, “It is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility” (p. 15). ([View Highlight](https://read.readwise.io/read/01hjf5dx8r9vh5t9b24a02kk57))
- the workshop aimed to further a taxonomy of intelligence across disciplines, a taxonomy that helps us to appreciate how different fields understand intelligence, what those fields have learned, and what questions remain open. ([View Highlight](https://read.readwise.io/read/01hjf5f0gsn41wtk5fk6p0d81s))
- The first fallacy is that narrow AI is on a continuum with general AI. The idea here is that progress in a particular domain of AI is ultimately progress toward domain general AI. ([View Highlight](https://read.readwise.io/read/01hjf5g04phms5pngrvd8w4ej5))
- The second fallacy is the tendency to think that things that are subjectively difficult for us
  are difficult in some objective sense and things that are subjectively easy for us are easy in some objective sense. This thinking leads us to believe that playing chess or Go should be difficult for AI systems and that perception and common sense should be comparatively easy ([View Highlight](https://read.readwise.io/read/01hjf5ghtt1mhjrc1gyjt9r7c5))
- The third fallacy is the tendency of researchers to uncritically accept the “wishful mnemonics”
  used to describe AI performance (McDermott, 1976, p. 4). For example, when we speak of an AI program that extracts information from texts, we might find it natural to say that the AI program is “reading” the texts. ([View Highlight](https://read.readwise.io/read/01hjf5gsdg16z96jht7tbghh7w))
- While thinking in terms of analogies is entirely natural and, on Mitchell’s view, central to intelligence, she here identifies a failure mode for this type of reasoning that often results in our “over attributing” abilities to AI. ([View Highlight](https://read.readwise.io/read/01hjf5h1rnvfgwnyzcvbk5yahx))
- The fourth fallacy is that intelligence and learning are best understood as phenomena going
  on exclusively inside the brain. The problem here is not that there is something over and above the brain responsible for intelligence, but rather that it is difficult to understand these phenomena unless we view the brain both as embodied and as situated in a particular environmental context. ([View Highlight](https://read.readwise.io/read/01hjf5hbgrm16q3vxy3zz7zt0r))
- On the contrary, work in developmental psychology suggests that human learning (which outperforms machine learning in many respects) is deeply dependent on this kind of interaction. ([View Highlight](https://read.readwise.io/read/01hjf5hr9dzdrwrxv10vyrr480))
- The fifth fallacy is that intelligence can be characterized “purely”—without considering the
  limitations, biases, strategies, or goals of any particular kind of intelligent agent ([View Highlight](https://read.readwise.io/read/01hjf5ngj65emd5fxztjq553bx))
- In framing these points, Mitchell outlined her own tentative view of intelligence. Intelligence
  involves a simulatable model of oneself and one’s environment that generates predictions and expectations. Further, it is closely coupled to the ability to affect the world—whether by manipulating physical objects or by altering the mental states of others. Finally, it centrally involves the ability to abstract from particular cases and apply lessons learned in one context to relevantly analogous contexts. ([View Highlight](https://read.readwise.io/read/01hjf5naxgpdhxwtyqfatx2kv4))
- Dennett begins by distinguishing intelligence from competence ([View Highlight](https://read.readwise.io/read/01hjf5pmdnvpfhbf3zex6rp313))
- To capture the difference between these cases, Dennett proposes that intelligence is the capacity
  to “know what to do when you don’t know what to do.” This distinguishes the ability to call forth a particular competence when appropriate, from the ability to reason about how best to solve a particular problem. ([View Highlight](https://read.readwise.io/read/01hjf5pwwv5zezb5kjpxybgdv4))
- Note that, on Dennett’s definition, merely deploying a problem-solving heuristic is not enough. Rather, real agents face problems that cannot be solved by any single heuristic, and ([View Highlight](https://read.readwise.io/read/01hjf5q6xa2xg3d4v2pdfjq27m))
- Instead, he suggests that humans adopt a particular division of labor with AI systems. AI systems will generate candidate solutions/strategies and humans will evaluate those candidates and select among them. As Dennett argues, this not only allows us to use AI systems to substantially extend our human capacities, but also to mitigate the risks associated with AI. ([View Highlight](https://read.readwise.io/read/01hjf5rymb69v49zg1mecpqtgx))
- This means that in order for humans to assume the proper role in Dennett’s generate and test approach, AI researchers should be careful not to see anthropomorphism as a goal of AI design. ([View Highlight](https://read.readwise.io/read/01hjf5rp96qsstd0mfev9rz9rj))
- A classic problem in machine learning is finding an appropriate trade-off between exploration and exploitation. This problem arises because once an agent discovers a beneficial behavioral strategy, deviating from that strategy in hopes of finding a better one means risking the benefits that could have been acquired by exploiting the original approach. ([View Highlight](https://read.readwise.io/read/01hjf5sh51gjeb53e617qzfhjt))
- A common solution is to begin learning with a bias toward exploration that gradually shifts into a bias toward exploitation. ([View Highlight](https://read.readwise.io/read/01hjf5sp1dmtq2v8k1rw8aanna))
- Gopnik argues that humans have taken a similar approach via adaptive changes to their life
  history (Gopnik, et al., 2020). ([View Highlight](https://read.readwise.io/read/01hjf5tnzk7bgsbh0q2w6df5j5))
- For this reason, Gopnik argues that menopause and the tendency of grandparents to exhibit special care for their grandchildren are both part of an evolutionary strategy for maximizing the fitness of older adults whose physical abilities have diminished and the fitness of children whose abilities/opportunities for learning are at their greatest ([View Highlight](https://read.readwise.io/read/01hjf5tgqc9gnz2s5azb2d8k6x))
- One worry for this kind of approach is that tuning AI systems to suggest “alien” inferences will
  undermine the scientific value of these inferences. ([View Highlight](https://read.readwise.io/read/01hjf5x028jk8ebpt6q5vm8pk4))
- Evans’s research has shown that tuning AI systems to “avoid the crowd” still results in those systems generating promising hypotheses that human researchers are unlikely to generate themselves (Sourati & Evans, 2021, p. 1). ([View Highlight](https://read.readwise.io/read/01hjf5x5ndpyqenqqst5pvx11w))
- In summary, Evans envisions AI as a kind of alien intelligence that (while not as adept at
  inference as human beings) can be tuned to explore the space of possible inferences in ways that human investigators are unlikely to pursue (Evans, 2020). ([View Highlight](https://read.readwise.io/read/01hjf5xbgc7t5j93ccp5ckk95x))
- Krakauer holds that intelligence is the acquisition of representations/rules (e.g., from the community) that facilitate successful problem solving. Unlike other speakers, he is more prepared to call a system “intelligent” when it exhibits competence in a narrow domain and ([View Highlight](https://read.readwise.io/read/01hjf5z68ev09srsnrp86gxdnk))
- Daniel Dennett, for example, spoke of less intelligent systems as exhibiting “competence without comprehension” and contrasted this with human intelligence. Krakauer, on the other hand, suggest that genuine intelligence is competence with a kind of “learned incomprehension” that comes from the acquisition of expertise. ([View Highlight](https://read.readwise.io/read/01hjf5zv44h7ha4tpdqh3ksehq))
- “Searle Inversion. ([View Highlight](https://read.readwise.io/read/01hjf6048sgx6168jae5cn50f5))
- rise to patterns in the forms of intelligence represented in the world. ([View Highlight](https://read.readwise.io/read/01hjf6132nz0pr47cszx09ky1w))
- A common image of a brain is as a
  collection of fixed cells defined by their connections to other cells and how those connections change over time. Liquid brains are those which not only change their connections but also their structure. ([View Highlight](https://read.readwise.io/read/01hjf61gr4eqd1gjqw4m6rmzy4))
- As the ants move about their environment, they form and break connections dynamically with their neighbors. However, this kind of flexibility, Sol´e suggests, may impose a trade-off on the complexity of individual members of such collectives ([View Highlight](https://read.readwise.io/read/01hjf61zrd0s6ayh98hsqxmhy6))
- Wheatley proposes that human social relationships can make us either more or less intelligent depending on the number and, more importantly, the type of connections we have with others. ([View Highlight](https://read.readwise.io/read/01hjf62b0phytf0apg2gpgqfex))
- First, we know that humans offload cognition to members of their social groups—e.g., by distributing skills and memories among group members. Second, we know that people differ in how they are connected to other members of their social network. ([View Highlight](https://read.readwise.io/read/01hjf62jjb05nsb7r48nxn6ecd))
- Wheatley’s third key point is that these connections shape how we think in profound and
  surprising ways. ([View Highlight](https://read.readwise.io/read/01hjf62w9s474xf6cj6txa0pza))
- Wheatley’s fourth key point is that some people in our network are better at enhancing our
  cognitive abilities than others. ([View Highlight](https://read.readwise.io/read/01hjf6363vfcr6906n18q1hh36))
- on building a model of what is depicted in a scene ([View Highlight](https://read.readwise.io/read/01hjf643n2jdswftgrpfa6xnpj))
- A key part of this kind of model building, Olshausen argues, is the ability to disentangle or factorize different aspects of a scene. ([View Highlight](https://read.readwise.io/read/01hjf64p3nkejsyxvysdva8tet))
- While this kind of factorization requires fairly strong constraints (e.g., priors) to operate effectively, Olshausen notes that even when we have isolated the relevant factors, the space of scenes which could be inferred is still staggering due to the combinatorial nature of the factors involved. ([View Highlight](https://read.readwise.io/read/01hjf654kp6ycwwg5m00hwp6cm))
- In summary, this suggests that intelligence researchers should pay closer attention to both the
  role of disentanglement in modeling and the role of neural realization in understanding these models ([View Highlight](https://read.readwise.io/read/01hjf66e03n6dngrks55bmwsxj))
- neural networks do not engage in explicit processes of factorization nor do they involve a realistic representation of the organization or computation abilities of actual neurons. ([View Highlight](https://read.readwise.io/read/01hjf667cmrkgt9dbvhfs9kg2g))
- Krakauer argues that this shows the degree to which reflexive control policies can underlie behavior we might initially believe require higher-level reasoning (e.g., modeling, simulation, and prediction). ([View Highlight](https://read.readwise.io/read/01hjf6741rwxrmwyzas6cwecp9))
- The key idea is that we have the ability to transform propositional knowledge into automatic, goal-directed responses (i.e., “intelligent reflexes”). These reflexes are governed by a control policy which maps states of the body to motor commands in a manner conducive to accomplishing particular goals. ([View Highlight](https://read.readwise.io/read/01hjf6846bqnmfhtty6r1etavb))
- This feature of human cognition has several advantages not least of these is that it allows human
  beings to build up a toolbox of useful control policies which can be activated under appropriate circumstances without requiring effortful thought. ([View Highlight](https://read.readwise.io/read/01hjf68cfdmcatqr78w3x5b9e7))
- She argues that biological intelligence is characterized by possessing valuable environmental maps, having the ability to use such maps to increase one’s fitness, and being able to change the world to make one’s maps more valuable. ([View Highlight](https://read.readwise.io/read/01hjf69n6n1b1tgxv51mtb4c9z))
- On this view, general intelligence amounts to having many maps or having maps that remain useful across diverse environments. ([View Highlight](https://read.readwise.io/read/01hjf6a8nz7tbd0hj9kehtn0an))
- Next, Moses discusses the distinctive features of human intelligence, arguing that uniquely
  human intelligence “includes understanding, meta-cognition, and a heightened ability to teach and learn” and that this intelligence “emerges from being conscious of our own understanding.” ([View Highlight](https://read.readwise.io/read/01hjf6agje2jqv11pdaf78h2ez))
- Following Douglas Hofstadter, she proposes that central to uniquely human understanding is the fact that we have a model or map of the world and a model of our own minds (Hofstadter, 2007). ([View Highlight](https://read.readwise.io/read/01hjf6arw1pb3yjq8kgrshbans))
- trade-offs by having different numbers of members pursuing each objective. They also have the ability to organize into systems and react to their own organization. In addition, they often blur the boundary between self and environment, and their cooperation is often driven by difficulty in distinguishing their own actions from those of others ([View Highlight](https://read.readwise.io/read/01hjf6bbm0xgzcpw4sqhdpq2s9))
- human intelligence could be augmented by enhancing the distinctive virtues of each form of intelligence discussed previously ([View Highlight](https://read.readwise.io/read/01hjf6br50vpssj4pxzhm4vfk7))
- Moses is also cautious about AI risks—not because she believes that AI will be radically different or vastly more intelligent than humans, but because the methods humans have already used to extend our intelligence (e.g., cultural transmission and social institutions) have already posed serious risks. ([View Highlight](https://read.readwise.io/read/01hjf6c6c6tgrc98c0b46mtprd))
- collective pattern formation, which focuses on how components interacting according to simple rules give rise to complex patterns (e.g., synchronized behavior). Here, the focus is on the emergent patterns of activity ([View Highlight](https://read.readwise.io/read/01hjf6dfrdtyzaqh8a908kspd8))
- solves a problem or maximizes fitness. ([View Highlight](https://read.readwise.io/read/01hjf6dnw6f35ay7dwbxeyen2n))
- the collective computation literature blends elements of theoretical computer science and mechanics to describe how collectives engage in computation. ([View Highlight](https://read.readwise.io/read/01hjf6dvyyfzqek2sg3929vthk))
- research aims at understanding the computational mechanisms by which collectives bring about adaptive outcomes. ([View Highlight](https://read.readwise.io/read/01hjf6e5z66war2y0nsgfpb8qc))
## New highlights added December 26, 2023 at 1:47 PM
- we need a formal framework that allows us to not only explain the mechanisms of collective computation, but also to understand how these mechanisms can be tuned or improved by evolution (or even learning) to produce adaptive outputs ([View Highlight](https://read.readwise.io/read/01hjm0m80dkx8czjqyb6c5ryxn))
- we must specify what variables are fixed by the environment, what variables the system can respond to, what behaviors are produced in aggregate, what problem those behaviors solve, what components there are/how those components are organized, the process by which those components produce solutions, and how a system determines when a solution has been found. ([View Highlight](https://read.readwise.io/read/01hjm0mjkepcd8csp9vysy7knf))
    - Note: Goal: “to rigorously characterize biological attention”
- several animals which lack many of our cognitive abilities actually exceed human performance on cognitive tests— even tests emphasizing rational decision making. ([View Highlight](https://read.readwise.io/read/01hjm0pk5ymmbcp5zz90zmhw8q))
- we need a better notion of intelligence to properly appreciate the distinctive cognitive abilities of diverse agents. ([View Highlight](https://read.readwise.io/read/01hjm0pzztegxdnjysktq2605p))
- Ecological rationality is the degree to which an agent’s toolbox of cognitive strategies and heuristics is adapted to its environment. ([View Highlight](https://read.readwise.io/read/01hjm0q8jtrqtzp4ds78c8dy10))
- By understanding intelligence as a kind of fit between a cognitive system and the environment, we can more completely and more rigorously characterize each item in an agent’s cognitive toolbox. ([View Highlight](https://read.readwise.io/read/01hjm0qbm62dfhb2sqz51045kf))
    - Note: Related to embodiment!
- The larger picture then is one in which researchers can (i) characterize a wide variety of cognitive
  strategies, (ii) characterize environments along a range of relevant dimensions, and (iii) apply a measure of fit to determine what strategies are appropriate in which environments ([View Highlight](https://read.readwise.io/read/01hjm0r73t7r0kdsmcw32202rs))
- be understood as a kind of meta-cognition, where we examine a problem, find a good representation of that problem, and select an appropriate cognitive tool for solving it ([View Highlight](https://read.readwise.io/read/01hjm0rj1s85xypssm6mgjx14e))
- For example, we might train several models and then train a meta-model which takes the predictions of those models as inputs (see e.g., Breiman, 1996; Yao et al., 2018). This “stacking” process allows the metamodel (i) to incorporate the predictions of the stacked models and (ii) to model and compensate for the pattern of biases they exhibit (Wolpert, 1992, p. 251). ([View Highlight](https://read.readwise.io/read/01hjm0sc3h6rafpz7a1rx4hcv8))
    - Note: Example of combining models to improve predictive accuracy
- Wolpert argues that stacking represents an improvement to the scientific method which has heretofore favored something closer to the single model approach of cross-validation ([View Highlight](https://read.readwise.io/read/01hjm0thwbk7g82ebqhcq101tj))
- With respect to artificial intelligence research, Wolpert argues that too much emphasis has been placed on the development of intelligent individuals. On the contrary, he suggests that general and super-human intelligence are likely to arise in a webbased ecology of AI systems and that this intelligence may be hard or impossible for humans to recognize from the outside. ([View Highlight](https://read.readwise.io/read/01hjm0v0gh300fa558j7gd4mn7))
- whether communities of AI systems were really different in kind from communities of humans ([View Highlight](https://read.readwise.io/read/01hjm0vftmtsh93kcjqtaap1dj))
    - Note: Open question! How is the notion of AI community different from human community?
- because the individual AI programs were Turing complete, the behavior of a community of them is, in a formal sense, uncomputable. As such, we cannot predict their behavior even in theory. ([View Highlight](https://read.readwise.io/read/01hjm0wpeft5v5aq2aayf3bw1x))
    - Note: What does this mean?
- Wolpert cited the willingness of engineers to forgo full understanding in favor of predictive accuracy as a model for future attitudes in science ([View Highlight](https://read.readwise.io/read/01hjm0xpgevzb9bh96nkx5b507))
    - Note: Does AI need to be intelligible? What is the goal of development? When is understanding spiritually or literally useful?
- Rather than giving evolution a highly-capable body from the outset and allowing it to shape behavior, evolution must solve the harder problem of finding good body/behavior combinations. ([View Highlight](https://read.readwise.io/read/01hjm101vqg0kmkvdhf1m5gnca))
- The larger picture of intelligence offered by Miikkulainen is that intelligence arises from the evolutionary optimization of neural networks under a range of realistic constraints, including resource limitation, body-brain co-evolution, competitive arms races, and the need for coordination. ([View Highlight](https://read.readwise.io/read/01hjm10kyvq997b796dmvsq2a1))
- She expresses skepticism that “intelligence” can ever be properly defined, but notes that intelligence seems to be a “collection of interacting capacities that involve information processing. ([View Highlight](https://read.readwise.io/read/01hjm113d2qw4dsmv69r8mbqxd))
- these diverse capacities are implemented in approximately the same kind of substrate (i.e., nervous systems) and that all these capacities evolved over time by the process of natural selection. This suggests that evolution may be of particular importance in understanding and developing artificial intelligence. ([View Highlight](https://read.readwise.io/read/01hjm11cg6a28c19abtrjmbb9z))
- Software might evolve at the level of individual programs, or at the level of software environments as they are used and modified by human communities. Forrest’s research focuses on the former, a type of evolutionary computation ([View Highlight](https://read.readwise.io/read/01hjm129d4q412ykg5tqqgnb0s))
    - Note: Look into evolutionary algorithms
- Forrest argues that biological evolution has a number of characteristics worth borrowing to advance the field of evolutionary computation. These include: open-endedness, major transitions, neutrality and drift, genotype/phenotype mappings, multi-objectivity, and co-evolution (Miikulainen & Forrest, 2021) ([View Highlight](https://read.readwise.io/read/01hjm13g4s026fjcs6hrf1nffj))
- One point of broad consensus was that intelligence can take multiple forms and that different definitions of intelligence are appropriate to different areas of inquiry. ([View Highlight](https://read.readwise.io/read/01hjm14849atcag0gpa2se28sv))
    - Note: Make a note gathering different definitions and forms of intelligence!
- towards general AI ([View Highlight](https://read.readwise.io/read/01hjm15k9dwa0bhadk2zz2pz9k))
- we have no idea what higher-level thinking really is despite the fact that we have made considerable progress in understanding more reflexive forms of intelligence. ([View Highlight](https://read.readwise.io/read/01hjm157c72b5xacn172qrrn2h))
- behavior of ant colonies as arising from a distinctive “liquid brain” architecture ([View Highlight](https://read.readwise.io/read/01hjm163s00hadr7ctq93g5sjx))
- “learned incomprehension” which underlies high-level performance in competitive puzzle solving. ([View Highlight](https://read.readwise.io/read/01hjm167w8tb4exbx0ksrqqjvg))
- effortful System 2-style cognition and automatic System 1-style cognition ([View Highlight](https://read.readwise.io/read/01hjm16jvsv3tk54gkcy6ffrrn))
- there was an emphasis on social groups as providing a kind of scaffolding for learning. ([View Highlight](https://read.readwise.io/read/01hjm17fjeyqcs4hnfgzhbk4kj))
- knowledge of novel techniques is disseminated to individuals in communities of competitive game players. ([View Highlight](https://read.readwise.io/read/01hjm17w85tx8qtfxkqvet84wr))
- social connections can help to enhance our intelligence by connecting us with diverse perspectives. ([View Highlight](https://read.readwise.io/read/01hjm180fjzgx36sd1r2dx1hr1))
- collective intelligence is a powerful tool for extending both biological and human intelligence. ([View Highlight](https://read.readwise.io/read/01hjm18cwcnwzjcwsw1ayf1yfs))
- general intelligence involves a kind of higher-order
  cognition. ([View Highlight](https://read.readwise.io/read/01hjm18vqcqg6tpsrkja8dzhy5))
- importance of evolution in shaping intelligence ([View Highlight](https://read.readwise.io/read/01hjm1974zbk716ttx9atxqxe0))
- constraints imposed by evolution are integral to understanding intelligence which (one may argue) is difficult to rigorously define without understanding an agent’s environment and limitations. ([View Highlight](https://read.readwise.io/read/01hjm19hemm3gdx09agp0kp0st))
- the constraints imposed by evolution are a key driver of intelligent behavior and should be replicated when evolving artificial agents. ([View Highlight](https://read.readwise.io/read/01hjm19rnw7mdv6bqg33a5shgq))
- the distinctive features of evolution as a design process, arguing that it has the potential to replace or augment existing approaches to software development if it can be tweaked and scaled so as to better emulate real-world evolutionary processes. ([View Highlight](https://read.readwise.io/read/01hjm1a5haf0gxms4fsete2ngn))
- evolution is the only known process that has resulted in robust general intelligence ([View Highlight](https://read.readwise.io/read/01hjm1acs2rvsgpbxwnhhpsjet))
- the importance
  of looking to diverse forms of natural intelligence when building or studying artificially intelligent systems. ([View Highlight](https://read.readwise.io/read/01hjm1arqve0asmncxf0d26rw8))
- the notion of ecological intelligence (i.e., intelligence as a kind of adaptation to one’s environment) can help us to more rigorously define intelligence by appealing to specific ecological contexts, contexts where the constraints and success conditions can be more clearly specified. ([View Highlight](https://read.readwise.io/read/01hjm1b8wfrb63bafr3myvek56))

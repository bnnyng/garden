# Deep learning (review)

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/uploaded_book_covers/profile_658243/1N98XL6qCECCqGyrGGFwNK4lJ-V8ClePajGYoNnKkxY-cover_bTqiQ0Y.png)

# Metadata
- Author: [[LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton]]
- Full Title: Deep learning (review)

- URL: http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf

# Highlights
- Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. ([View Highlight](https://read.readwise.io/read/01h9kvqb1ttptc9cvhv1mh6qcr))
- Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. ([View Highlight](https://read.readwise.io/read/01h9kvr3swb55ykxhdstavf94k))
- Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. ([View Highlight](https://read.readwise.io/read/01h9kvt92js0ywgzdcy03fgasg))
- Deep-learning methods are representation-learning methods with multiple levels of representa- tion, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. ([View Highlight](https://read.readwise.io/read/01h9kvtr5m4nz03skw80dag6e4))
- To properly adjust the weight vector, the learning algorithm com- putes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount. The weight vector is then adjusted in the opposite direc- tion to the gradient vector. ([View Highlight](https://read.readwise.io/read/01h9kvx0hypxqk0qtpq5d05nw5))

---
citekey: "[@2023chiang]"
​aliases:
  - Will A.I. Become the New McKinsey? | The New Yorker
tag:
  - literature-note
title: Article | Will A.I. Become the New McKinsey?
year: 2023
permalink: https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey
publish: "true"
date: 2024-08-15
lastmod: 2024-08-15T20:37:25-07:00
---
> Chiang, T. (2023). _Will A.I. Become the New McKinsey? | The New Yorker_. [https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey](https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey)

---
# Summary

Chiang argues that the primary risk of AI is its “execution” and strengthening of capitalism. He begins with an analogy between AI and management consulting firms like McKinsey, which are used by corporations to accrue wealth at the expense of human consumers and workers. 

Today, technology, capitalism, and progress are conflated. However, because technology and capitalism have not led to increased standards of living in the past, there is no reason to suppose it will do so today. In fact, the idea that progress will follow automatically assumes that the world we live in already has certain utopian features, such as UBI.

Chiang cites addressing wealth inequality and “taming capitalism” as work that will help build a better world. The article ends with an imperative for technologists working on AI to self-examine their complicity in capitalism’s injustices. If AI developers claim to be creating a world-changing technology, then they also have an ethical obligation to ensure that technology helps the world.

---
# Reading notes

### AI assists capital at the expense of labor

- People rely on metaphors to describe new and unfamiliar things. Most metaphors for AI are bad.
- Chiang argues that an appropriate metaphor for AI risk is a management-consulting firm like McKinsey.
	- Machine learning helps draw users to social media; McKinsey helped Purdue Pharma escalate sales of OxyContin during the opioid epidemic. In both cases, the agent helps corporations sell products and services at the detriment of consumers.
	- AI is a cheap replacement for human workers; McKinsey helped normalize mass layoffs to increase stock prices and executive compensation. In both cases, the agent causes economic disruption; McKinsey “contributed to the destruction of the middle class in America.”

>A former McKinsey employee has described the company as “[capital’s willing executioners](https://www.currentaffairs.org/2019/02/mckinsey-company-capitals-willing-executioners#:~:text=An%20insider's%20perspective%20on%20how,spreads%20the%20gospel%20of%20capitalism%E2%80%A6&text=The%20author%20of%20this%20piece%20has%20chosen%20to%20maintain%20anonymity.)”: if you want something done but don’t want to get your hands dirty, McKinsey will do it for you. That escape from accountability is one of the most valuable services that management consultancies provide. Bosses have certain goals, but don’t want to be blamed for doing what’s necessary to achieve those goals; by hiring consultants, management can say that they were just following independent, expert advice.

- Chiang focuses on the “execution” role of management consultancies like McKinsey. The main benefit of such consultancies is removing blame from the client.
	- This doesn’t quite align with the claim in Chiang’s referenced [[@2019lovely]], which begins by arguing that McKinsey’s secrecy allows them to also avoid blame. Perhaps things have changed?
	- Similarly, AI allows companies to blame “the algorithm” for any negative effects.
- To prevent AI from becoming another version of McKinsey, we must also define the term “artificial intelligence” itself.
	- If AI is a set of technologies that helps companies reduce cost, we risk it parallelling McKinsey’s role as “capital’s willing executioners.”
	- If AI as a semi-autonomous agent that obediently solves particular human problems, we risk the solution space being one that makes people’s lives worse.
- Constraining AI is not a solution, because clients will always use an AI that can execute their goals instead.
- Chiang specifies that when he criticizes “capitalism,” he refers to a system where capital wealth is concentrated among a small group of people, accumulated off the labor of others over whom they wield power.
	- Chiang notes that there is not such a thing as a labor consulting firm, so one cannot find the same analogy between AI and something that helps workers.

>Is there a way for AI to do something other than sharpen the knife blade of capitalism? … AI assists capital at the expense of labor. … Can AI do anything to assist workers instead of management?

>Some might say that it’s not the job of A.I. to oppose capitalism. That may be true, but it’s not the job of A.I. to strengthen capitalism, either. Yet that is what it currently does. If we cannot come up with ways for A.I. to reduce the concentration of wealth, then I’d say it’s hard to argue that A.I. is a neutral technology, let alone a beneficial one.

### “We should all strive to be Luddites”

- Universal basic income is not a solution for AI-driven unemployment because we do not currently have UBI. This proposal is a way for AI developers to pass social responsibility to the government.
	- Accelerationists suggest that once AI has made people’s lives bad enough, the government is sure to step in.
	- Chiang compares with Susan Sarandon and Slavoj Zizek advocating for voting for Trump during the 2016 election, which they believed would “shock the system” into change. This is a leftist form of [[Accelerationism]].
- If we are to be intentional about an accelerationist approach to the problems of AI, then we also face the risks of accelerationism: we do not know when positive change will happen. In the meantime, we can be certain of “significant pain and suffering in the short term.”

>Capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives.

- Chiang notes that the [[Luddite|Luddites]], which is now short-hand for someone who irrationally opposes new technologies, were not opposed to the advancements of industrialization but the economic exploitations and worsened quality of life that came with it.
	- When we encounter the term “Luddite,” we should examine the goals of both accused and accuser.
- Technology, capitalism, and progress have all been conflated. When you criticize one, people assume you are criticizing all the others.
	- As capitalism strengthens, laborers have worse lives and money is concentrated in a small group of shareholders. Thus, capitalism cannot be the same as progress.
- Chiang’s ideal future is one where everyone can engage in [[The contemplative life]].
	- In the next few decades, only one of capital and labor will become more powerful. 
	- The current use of AI is in favor of capital. It does not lead us closer to that ideal future.

### Technology does not increase standards of living

- New technology has not lead to increased standards of living.
	- In the 1980s US, the information-technology revolution happened at the same time as median household incomes fell in comparison to per-capita GDP.
	- Costs of real estate, college tuition, and healthcare have risen faster than inflation.
	- Today, it is rare to support a family on a single income.
- In contrast to the “automation path” where AI replaces human workers, the “augmentation path” proposes ways for AI to increase individual worker productivity.
	- However, personal computers are an example of successful augmentation without economic improvement. 
	- We need economic policies to distribute the benefits of technology. Unfortunately, there is no precedence for such policies.

>It would be convenient if we could assume that a utopian future is right around the corner and develop technology for use in that future. But the fact that a given technology would be helpful in a utopia does not imply that it’s helpful now.

- We have to evaluate the effects of AI in our current world and problems.

### Building a better world requires hard work

- Sociologist Erik Olin Wright defines several strategies to respond to capitalism’s harms.
	- Taming capitalism involves government intervention.
	- Resisting capitalism involves grassroots activism and labor unions.
- Workers at the Lucas Aerospace Corporation are an example of “trying to steer capitalism in a more human direction.”

>In 1976, the workers at the Lucas Aerospace Corporation in Birmingham, England, were facing layoffs because of cuts in defense spending. In response, the shop stewards produced a document known as the Lucas Plan, which described a hundred and fifty “socially useful products,” ranging from dialysis machines to wind turbines and hybrid engines for cars, that the workforce could build with its existing skills and equipment rather than being laid off.

- In the end, Chiang turns his attention to the “technologists” currently developing AI who view it as a salve to the world’s problems.
	- Technologists are different from other corporate workers because of the impact they claim AI will have. This gives them an ethical obligation beyond other industries to ensure AI will make the world better.
	- Technologists are responsible to question their own assumptions about AI’s benefits and their complicity in capitalism’s injustices.
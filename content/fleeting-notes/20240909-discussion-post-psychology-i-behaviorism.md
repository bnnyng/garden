---
tags:
  - fleeting-note
  - PHIL-UN2655
date: 2024-09-09 09:30
lastmod: 2024-09-09T10:22:02-04:00
aliases:
  - "Discussion Post: Behaviorism and Skinner's Philosophy"
---
# Sketch

- Operant conditioning
	- Surprised by degree to which I found Skinner’s ideas insightful re: operant behavior
		- Familiar with the concept of RL, but connection to Darwinian evolution is new to me
	- Operant behavior – surely not all learning can be explained, thinking of AlphaProof
	- [[Complexity is the study of teleonomic matter, after Krakauer]]
- Self-knowledge
	- Agreed with notions of language

---
# Discussion post

I found myself strongly agreeing with Skinner that self-knowledge is a social product: ”It is social reinforcement which leads the individual to know himself. It is only through the gradual growth of a verbal community that the individual becomes ‘conscious.’ He comes to see himself only as others see him, or at least only as others insist that he see himself” (Skinner, quoted in [@1991flanagan]). My agreement comes from some priors I have in the philosophy of mathematics. If we take seriously Flanagan’s analogy between linguistic descriptions and geometric descriptions (e.g., the Pythagorean theorem), then the knowledge-is-linguistic perspective is similar to mathematical realism; that is, that descriptions in terms of words, equations, and mathematical objects are themselves physical properties of the universe that exist outside of us. This does not make sense to me. What does it mean for number to exist without us thinking about it? I think that, among other purposes, mathematics is an efficient formal system for compressing information about physical reality, perhaps the most efficient that our species has; even if it’s not real, it’s very useful. Similarly, the problem of other-minds doesn’t strike me as a reason to not use personal accounts in psychology: as long as we share in the “language game,” these representations of other-minds will still convey some information.

Also, the connection between operant conditioning (reinforcement learning?) and natural selection was a new insight for me. The emphasis on operant conditioning as a teleological account makes me wonder if there is a way to view cognitive science more broadly in terms of goals or purposes, rather than information-processing. Again, an example from the mathematical world: the recent success of AlphaProof, an proof-solving RL algorithm that operates over mathematical statements formalized in the Lean language, shows fairly effective information-processing, but is deeply unsatisfying as a model of human mathematical reasoning. We can characterize AlphaProof’s “cognition” by saying its goal is to maximize a reward function, while most would agree that this is not the case for human cognition: no person solves a math problem by iterating through potential branches of state spaces until they reach the theorem they’re trying to prove. Connecting back to the natural selection component, we are also subject to purposeful optimization at evolutionary timescales, an RL algorithm less obviously so.
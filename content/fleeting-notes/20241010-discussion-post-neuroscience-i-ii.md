---
aliases:
  - "Discussion Post: Neuron Doctrine, Cyberneticism, and Mathematical Neural Modeling"
tags:
  - fleeting-note
  - PHIL-UN2655
date: 2024-10-10 11:45
lastmod: 2024-10-15T11:46:54-04:00
---
# Neuroscience I

## Lecture notes

- “[Any account of concrete computation must solve this problem](https://plato.stanford.edu/entries/computation-physicalsystems/)”: dotted lines must be explained.
	- Most accounts try to avoid the trivialization that “everything is computing everything.”
![[Pasted image 20241010122123.png]]
- **Minimal pancomputationalism:** Do planets compute their own trajectories? (i.e., f(time) = location) – computing vs. being described by a computation
	- Is there a problem? Not really, doesn’t threaten “computationalism”, but it kind of points to me that computation is not sufficient for “mentality”; a more general theory
	- Every physical system computes its own description

---

# Neuroscience II
## Sketch

[[@1959lettvin]]

- How can we be certain of anything in neuroscience? Attribution of different areas of the brain to different functions—but don’t we know in general, things are multiply realized? Visual stream is the favorite success story in neuroscience for a reason: “higher” cognitive functions seem to have greater degrees of freedom w.r.t. what parts of the brain they use
- Bottom-up approach to cognition: perceptual abilities are matched to the environment (e.g., frog’s eyes are matched to things that look like flies), other examples of matched filtering—if brain structure and energy goes to this one function, then cognitive capacities are constrained

[[@2021lindsay]]
- Hubert & Wiesel → CNNs

## Discussion post

I’m exposing my computational chauvinism, but reading [[@1997gross]] from the perspective of modern functional imaging, connetonomics, theoretical neuroscience, etc., it’s hard not to see the pre-20th century, pre-[[@1943mcculloch]]-type computational accounts of the nervous system as something like astrology. Aside from the dynamics within and between individual neurons, which we can more or less describe with principles of physics, it seems challenging to give a definitive functional account of broader brain structures or “population codes.” Perceptual streams like the visual system seem like an exceptionally straightforward part of the brain to understand (and perhaps why the visual system is a favorite success story, from [[@1959lettvin]] to Hubert & Wiesel to modern convolutional neural networks) because the structures themselves, like the frog’s ganglion cells, are matched filters for regularities in the environment; [[@2016warrant]] describes more of these “sensory matched filters,” which are particularly obvious in organisms with constrained metabolisms like flies. I think what makes both individual neurons and sensory systems amenable to description is their limited degrees of freedom, or what operations they can realize. But this makes them entirely uninteresting for understanding mentality; for example, the highly specified visual filters of the male blowfly described by [[@2016warrant]] mean that the load of information processing is mostly borne by the sensory neurons themselves, a bottom-up cognitive constraint. On the other hand, populations of neurons are paradigmatic examples of multiple realizability, with countless clinical examples of people who have lost substantial portions of their brains and more or less recovered normal behavior. I am very curious about the relationship between various types of constraints: metabolic, computational (which perhaps depends on the metabolism that implements it), and cognitive (which computationalist would assume share metabolic and computational constraints, a priori?). Alternatively, what counts as a “resource” for human cognition?

## Lecture notes


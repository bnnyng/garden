---
aliases:
  - "Reflection Essay: Efficient Coding and Metabolic Cost"
tags:
  - fleeting-note
date: 2024-10-01 21:40
lastmod: 2024-10-01T23:00:46-04:00
---
# Notes
[[@2008okawa]]
- Rods and cones consume similar amounts of energy in darkness, but rods consume significantly less in light
- Eye evolved around reducing energy use by photoreceptors

[[@2003lennie]]
- Spike energy usage is inversely related to number of active neurons—more expensive = less active 
- Task “difficulty” = how much cortex is active

[[@2022quintela-lopez]]
- The brain’s wiring, space, time, and coding are all optimized to maximize information flow while minimizing energy use
	- When does this information become meaningful/have semantic content? Only via population code—otherwise we couldn’t come up with a general theory of computation (we get specific “grandmother” neurons)
	- How is semantically meaningful information using energy?
- Energy consumption puts constraints on evolutionary “design” of the nervous system

---
# Reflection essay

Energy constraints influence both computational trade-offs at the neuronal level and, in the words of [[@2022quintela-lopez]], evolutionary “design” of the brain. For example, [[@2008okawa]] showed that in the visual system of diurnal animals, rod cells and cone cells consume similar levels of energy in darkness, but rod cells become drastically more energy conserving. This is because rod cells actively maintain a depolarized state in darkness by pumping out ions, while those ion channels are closed to achieve a hyperpolarized state while in bright light. This shows energy optimization at the level of individual cells, if we assume that this is more efficient for animals that spend a greater amount of time in daylight. Further, lack of a similar difference for cone cells motivates structural-level optimization: “As a rule, it should be more economical to limit the number of cones and place them in a specialized region of high acuity such as the fovea or visual streak” [[@2008okawa]]. 

[[@2008okawa]] conclude that “photoreceptor energy consumption can play a significant role in eye evolution.” The other readings make similar references to fine-grained structures affecting the evolution of coarser ones, but I’m still convincing myself this makes intuitive sense. On one hand, cells are fundamentally the units being affected by the energy bottleneck. On the other hand, why shouldn’t higher-level constraints in the environment (e.g., that which supplies the organism with sensory experiences) influence the development of cell structure? I suppose that at the time in evolutionary history that neurons differentiated from other cells, the “environment” for those prehistoric organisms may well have been at a chemical/molecular granularity. Organized collections of cells can change their structure at much shorter time scales than the individual components. I wonder if eventually, feedback from coarser/higher-level interactions between organisms and environment will affect the individual cell structure, or if this is as optimized as we can realistically get?

 At the end of [[@2003lennie]], the author suggests a “natural metric for characterizing aggregate task difficulty: how much the cortex is active.” As a cognitive science major, I am naturally inclined to wonder about how this extends to system-level “cognitive” tasks (which are not necessarily conscious), beyond sensory/perceptual information processing. I am not sure how much this sort of question can actually be empirically investigated: I find that often in cognitive science, both physical (i.e., neuroscientific) and algorithmic (i.e., substrate-neutral) accounts of information processing in the brain conflate Shannon information—a quantity that reduces uncertainty about the source of formation—with semantic information—the mutual information between different states of a cognitive system. As long as we are discussing a chain of action potentials, we are safely in Shannon information territory, but I think things get sketchy once we refer to parts of this chain as, e.g., in last week’s readings, making a decision to perform an action. Digression aside, given that our brain varies in evolutionary “degrees of freedom” at different structural levels, I wonder if organisms optimize at for semantic information? In theory, semantic information of a signal should be irrelevant for physically transmitting it, since otherwise we would not have a general notion of “information theory.” But the existence of a feedback loop between semantics and brain anatomy would suggest, for example, a neural basis for human exceptionalism on Earth.
---
aliases:
  - CUMMW
tags:
  - project
publish: 
date: 2024-01-04 14:57
lastmod: 2024-01-17T15:57:05-08:00
---
# To do
## Additional preparation

- [ ] Study and attempt to code paper 12 method (novel Bayesian model)
- [ ] Study and attempt to code paper 3 method (epidemiology-like differential equations)
- [ ] Study solutions to the other data insights question

---
# Notes

## Problem

- Tasks:
	- Develop a model to explain the variation in reported results, use the model to create a prediction interval for the number of reported results on a given date.
	- Determine if any attributes of the word affect the percentage of scores reported in Hard Mode.
	- Develop a model to predict distribution of reported results (associated percentages for guesses in 1-7+ tries) for a future solution word on a future date.
	- Develop a model to classify solution words by difficulty.
	- List other interesting features of data set.
- Components:
	- One-page summary sheet
	- Table of contents
	- Complete solution
	- One to two-page letter to the Puzzle Editor of the NYT, summarizing results
	- Reference list

## Judges’ commentary

| Component                                  | Judges’ tips                                                                                                                                                                                                                              | Takeaways                                                                                                                                                                              |
| ------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Executive summary and letter to the editor | - **Executive summary** and **letter to the edito**r are used to decide whether to move paper to final judging. <br>- Provide concise overview of problem, modeling process, and results.                                                 | - Worth spending extra time on these. <br>- Judges favor papers with overview of all three parts.<br>- Write for non-technical audience. <br> - MUST justify use of modeling approach. |
| Predicting results                         | - Top papers had *well-defined prediction intervals* with *effective measures of uncertainty*. <br> - Visualization appreciated: heat bands, prediction interval graph. <br>- Assess statistical significance of regression coefficients. | - Any prediction interval MUST have a robust measure of uncertainty (e.g., confidence interval).                                                                                       |
| Distribution of reported results           | - Best practice: validate predictive model by testing on a word with known results. <br>- Again, use visualizations! <br>- Justify model with goodness of fit?                                                                       | - As above, provide prediction interval with a robust measure of uncertainty. <br>- Thoroughly analyze uncertainties and confidence levels.                                            |
| Difficulty ranking                         | - Best teams identified specific word attributes. <br>- Common approaches were clustering, PCA.                                                                                                                                           | - Clearly explain clustering process and interpretation of results. <br> - Support conclusions with specific examples that can be verified through data with visualizations.           |
| Other interesting features                 | - Teams assumed Wordle was played fairly – not the case, Often cheating!                                                                                                                                                                  | - Clearly explain and justify observations (e.g., correlation matrix to support conclusions about relationships between word features).                                                |
| Sensitivity analysis                                           | - *Sensitivity* indicates model performance and opportunity to assess robustness to assumptions. <br>- Perform sensitivity analysis on ANY estimated parameter, input variables themselves (e.g., testing weights).                                                                                                                                                                                                                                          |                                                                                                                                                                                        |
| Strengths and weaknessess                  |                                                                                                                                                                                                                                           | - Identify improvements that could be made without time constraints!                                                                                                                                                                                       |

## Solutions

### General

- Use word bank or corpus of data to identify important attributes of words in general?

### Key terms

- **Bootstrap method** = repeatedly sampling with replacement from observed data, fitting predictive model to each resampled dataset, using the resulting distribution of predicted values to quantify uncertainty about predictions.
	- **Bootstrap sampling** = randomly sampling with replacement.
	- Alternatives: cross-validation (resampling too; usually used for assessing model performance – bootstrap is more general, used for statistical problems); Monte Carlo (possibly more general)
- **Bootstrap aggregating (bagging)** = creating subsets of training data with **bootstrap sampling**, train a base model on that subset, aggregate the predictions of each model to make predictions on new data.
	- Aggregate can be **voting** for classification, **average** for regression.

### Summaries of methods
| Paper | Predicting results | Word attributes | Distribution of results | Word difficulty ranking | Other notes |
| ---- | ---- | ---- | ---- | ---- | ---- |
| 1 | **Gated Recurrent Unit (GRU)** | “Data analysis”; identified attributes had no impact on difficulty level | **Grid-search random forest **(GSRF) – random forest using best combination of hyperparameters | K-Means++ |  |
| 2 | **SIRS model** – compartmental model, often used for infectious diseases! | Extracted word attributes from a database and use **multiple linear regression** to investigate relationship between attributes and hard mode scores – none significant. | **Back-propagation (BP) NN** based on extracted word attributes. | K-means++ to divide words into easy, medium, hard categories |  |
| 3 | **SIR model** inspired “epidemiology-like differential equation”; **genetic algorithm** to minimize MSE; **bootstrap** method | “Regularity” and “purity” related to word difficulty. | **KNN regression** because predicted distribution sums to zero (❗ why?) | Found correlated features with **correlation matrix**, classify features with **KNN classifier**, KNN classifier to classify features. |  |
| 4 | **Autoregressive integrated moving average (ARIMA)** – time series model to explain variation and predict future value | **LightGBM** | **Gradient-boosted decision trees (GBDT)** and **multi-gate mixture of experts (MMoE)** | **K-means** and **LightGBM** |  |
| 5 | **ARIMA-BP** using **bootstrap** method | **Multiple linear regression model** using word attributes (mixed qualitative and quantitative) | Preprocessed data with spherical coordinate transformation to ensure output around 100%; **long short-term memory (LSTM)** | **Gaussian mixture model (GMM)** – representing normally distributed populations |  |
| 6 | **ARIMA** for “linear part”, **LSTM** for non-linear | **Spearman correlation coefficient** for five word attributes and difficult mode | Stacking model with linear regression (Ridge regression, Lasso regression) and tree models (XGBoost, LightGBM) | Simplify metrics using PCA, use **GMM** to cluster |  |
| 7 | LSTM |  | Seven separate XGBoost models | **Support vector machine (SVM)** with **radial basis function (RBF)** kernel – “kernel trick” maps input data into higher-dimensional space |  |
| 8 | **Gaussian regression** to predict “trend signs of report numbers”; **non-homogenous Poisson process** to predict fluctuations. |  | **Integrated BP NN** based on **bagging** | **K means** as *induction model* to divide difficulty into 4 classes; **Pearson coefficients** for *classification model* |  |
| 9 | **Prophet-based time-series prediction model** | **Higher-order partial correlation coefficients** for word attributes and proportion of difficulty reports | **Multi-objective regression prediction** framework | **K-means** |  |
| 10 | “Dynamic system” inspired by **SIR model** – captures changes in population. Original model did not work well, slightly adjusted. |  | **Simulation algorithm** and **gradient descent** to mimic behavior of players guessing words and sharing game results | **K means** into three clusters, **random forest model** to divide words based on attributes. | - Liked that solutions were included in the summary <br>- Effective flowchart of process in introduction <br>- Constructed indicators first |
| 11 | **ARIMA** | **Multiple linear regression model** to find relevant attributes | **Gaussian process regression model** combined with **Markov chain** model for Wordle process |  |  |
| ⭐ 12 | Novel “subset entropy” metric to quantify average amount of information revealed after initial guesses; represent distribution using two variables. | **Lasso regression** to isolate most relevant predictors of word difficulty; used **Stanford GraphBase** word bank |  |  | Develop “comprehensive Bayesian model” with three submodels |

---
# Log

## Stage 3 – due 2024-01-21

2024-01-17
- "What characterizes Problem C is that it requires teams to deal with uncertainty, due to underlying randomness in the data, statistical imprecision in forecasts, or uncertainty in the estimation of model parameters. Teams that address these issues well in future contests will continue to be ranked high by the judges."
	- #question How to quantify uncertainty in model parameters?
	- Statistical imprecision can be addressed with confidence intervals, error analysis.

2024-01-16
- Others to drop

2024-01-15
- Need to follow a more cohesive design path next time:
	- Start by inspecting features and removing redundancies
	- Choose the models themselves, fit on all/reduced data to compare datasets
	- Get best hyperparameters for models on the best datasets
- Next to do:
	- Hyperparameter tuning for all base models
	- Fit base models and make predictions on reduced dataset
	- Hyperparameter tuning for the meta model

2024-01-15
- Thoughts on additional things to do before write-up:
	- Try Bayesian neural net
	- Sensitivity analysis
- Questions for meeting with mentor:
	- Selection of neural network for second stage—issues? Recommend something else?
	- Modeling as time series data vs. not?
	- Other ways to measure uncertainty?
	- What to do for data manipulation questions in general? Is it okay that we just choose an ML model? What strategies can we use to interpret?
	- Competition strategies—how to approach problem, literature review? How to allocate time? What to do if getting stuck?
- Tips:
	- Ensembles look good
	- Try something more novel for predicting reported results
	- Don’t treat try distribution task as sequential – can use normal linear regression, decision tree (or acknowledge limitations of current method, namely summing up to 100/returning interval)
- To do:
	- Analyze correlations between “important” features and distribution difficulty

## Stage 2 – due 2024-01-14

2024-01-14
- Attempted to code Bayesian neural network
- After discussion with Elliot at 3; next steps:
	- Analyze uncertainties in the model
	- Do usual statistical analyses
	- Make hard mode prediction for EERIE
- Extra:
	- Try a more basic model
	- Try out BNN with all linear layers – no time dependence
- Future:
	- Aggregate place and letter distribution feats

2024-01-13
- Notes on Bayesian neural networks
	- https://www.cs.toronto.edu/~duvenaud/distill_bayes_net/public/
		- NNs are function approximators with many parameters (weights and biases)
		- BNNs help with overfitting – good for small dataset, don’t want to use traditional NN (MLE)

2024-01-11
- To discuss with team:
	- Should decide on word attributes today 
		- Something to account for Wordle tile colors — frequency (how to measure?) of words with green/yellow/either color
		- Part of speech
		- How often each letter pair is adjacent to each other 
	- How to generate interval vs. point estimate?

2024-01-10 – Literature review
- To discuss with team:
	- What to do about % of hard mode scores?
		- Impacted by # of regular players (friend who said they choose hard mode every time)
		- More total people in beginning = more people trying hard mode and failing at it = different distribution?
	- We should probably number the problems to give our folder some kind of naming convention – begin file names (code and datasets) with the appropriate number

## Stage 1 – due 2024-01-08

2024-01-09 – **CALL: Stage 1 review**
- Errors are not unexpected; some of the analysis was harsh!
	- Indicating that we really understand what really is going on in the paper and the problem
	- Getting a good idea of how to improve
- First stage when you approach a new problem: literature review!
	- Similar problem contexts
	- What methods have been used in the past
	- Try to engineer these methods to solve the problem at hand
- Don’t need to approach the paper as an expert; just have enough knowledge to carry out analysis
- Asked about using ML:
	- Make sure usage of model is justified
	- Moving forward, can either improve upon hyperparameters or choose an entirely different approach
- Having a disciplined approach to work:
	- Be clear about assumptions, always update it
	- Cross-reference formatting in the paper
	- Have a table of parameters and values
	- Keep a log of work history and changes
- Dragomir’s suggestion: try to implement new things, but keep a log of changes
	- If a new model is used, make a note of it, include all references used

2024-01-08
- General questions (for next group call and Q&A?):
	- How much to focus on reproducibility?
	- Also, results are not always interpretable? – is this something that judges will care about in the competition?
	- LaTeX template allowed?
- Other things to learn for the competition:
	- Making diagrams in LaTeX
	- Formatting documents in LaTeX – start during Stage 2?
- Questions for the team:
	- Don’t understand the spherical transformation either, seems like the main motivation is summing to 1…which can be done by dividing by total etc. Can someone explain? What does the output even mean? Reverse transformation?
	- Why use *total* number of players at all? Would be more useful to determine the number of players in hard mode, since that is likely to affect # of tries
	- What can I help with? Write-up, coding

2024-01-07 – Work on Stage 1
- Discuss with team:
	- Do WE know the actual values for each of these? How can we determine if our model has been improved, lol? What measures?
	- 3 - ARIMA and BP
		- Looking at why “favor” isn’t a 5-letter word…maybe just doesn’t include all 5-letter words?
		- Slight differences on ARIMA estimate, not sure if strategy was correct
		- No details on “BP neural network” – training, hyperparameters, etc.
	- 4 - Word attributes vs hard mode
		- Improvement: could do some feature discovery ourselves using a real database of words
	- 5 - LSTM for predicting percentages
		- No details on training the NN?
		- Emphasis on sensitivity and error analysis
	- Stated model improvements
		- 6 - GMM clustering model for word difficulty
		- 7 - More algorithms to explore interesting dataset features (probably due to time constraints)
- For Stage 2, can fudge the rules and “improve” model by using an entirely different model for a given section? i.e., trying strategy from part 3
- Things learned:
	- Using `nltk` for language tasks, like parts of speech
	- Using `SenticNet`for emotional polarity

2024-01-06 – Notes on MCM C
- To discuss with team:
	- Cleaning and modifying data? 
		- Fixed data errors
	- Pick and choose models for our stage? – divide into three parts?
	- Share code in Google folders, Colab
	- Use a Google Doc for Stage 1 before typesetting
		- For writeup, make shared Overleaf document
		- Eventually can make template
- Problems of interest
	- 12
		- Pros: unique, learning about info theory; impressive predicted results
		- Cons: might be difficult to improve upon given limited background; might be difficult to apply learning to novel problems

2024-01-04 – Interesting problems
1. MCM Problem A (continuous): Drought-stricken plant communities
	1. Judges’ comments
	2. Approaches
		1. Cellular automata
2. MCM Problem C (data insights): Wordle
3. ICM Problem D (network science): Network for UN sustainability goals
4. MCM Problem D (data insights): Used sailboat pricing
---
aliases:
  - mental model
  - mental representation
  - mental models
  - mental representations
  - two oppositions
tags:
  - permanent-note
  - topic-physics-complexity
  - seed
publish: "true"
date: 2024-07-23
lastmod: 2024-08-16T16:30:10-07:00
---
In a talk for the 2024 SFI undergraduate research program, Simon DeDeo described how instead of interacting directly with reality, the mind interacts with “the symbolic,” a third thing used for seeing through. This is necessary because the real—in the Lacanian sense of what is resistant to formalization—is too big for our minds to process. 

(Tangent #1. Compare this with [[Life is a lineage of information, after Walker]]: because life is contingent on structures that have already been built, there exists an “adjacent impossible” of things that we cannot conceive of. However, Walker also claims that imagination *causes* the reality that will be built, and the universe we imagine is bigger than the universe [[Narratives become and make reality|we can physically construct]]. I have yet to square these ideas—is the signature of life to reshape reality such that it squares precisely with our mental models?)

(Tangent #2. More generally, internal models are used by all [[Complex systems have nontrivial emergent and self-organizing behaviors|complex adaptive systems]]: “Everything adaptive has a model.” How does the sense of reality being “too big” differ across adaptive systems, if at all? …What is the relationship between a mental model and unconscious thought?)

There are two “oppositions” in how we use mental models:
- [[Model as sense-making device vs. model as prediction device]]
- [[Model as pattern vs. model as measure]]

*How do we get a grip on this “third object”?* Take mathematics as an example. While trying to prove a theorem, a mathematician interacts with the space of all possible proofs by building a mental representation of the space of proof structures. If mathematicians are working collaboratively, like in the [[2024-polymetamath-research-log|Polymath project]], they must also model each others’ possible models. Modes of communication—speech, text, gesture—not only enable sharing models, but also talking about and assessing models (see also: [[Self-reference]]). [[Mathematical communication is most effective in subfields due to shared patterns of thinking|Mathematical subfields]] exemplify models shared between individuals (though to what extent?). 

But what about models that are not shared wholes, but distributed? [[@2024wolpert|Wolpert & Kinney (2024)]] essentially theorize that [[Mathematical ground truth is the set of answers given by a future community of mathematicians|mathematical ground truth]] is such a distributed model (then use a [[All models are wrong, but some are useful|mathematical model]] to get a better grasp on the implications of that theory…like a Russian doll!). This truth is clearly distributed because there is not one mathematician that knows all of mathematics, but is it actually a model? Perhaps this is a case of the mental representation squaring precisely with “reality,” to the extent that math can be considered real (alternatively, calling this a model is a category mistake).
---
tags:
  - daily-note
lastmod: 2024-06-21T16:46:58-06:00
---
>[!example] Reminder
>Be the most excellent version of myself I can be, one day at a time. If I look back on today specifically, I want to be proud of what I did and who I am.

# To do

> What are the top three *most important* things I need to do today?

- [x] Prepare for chat with Sara Walker
	- [x] Skim papers – mathematics, assembly theory
	- [ ] Solidify main conversation topics, turn note into mind map 
- [ ] Continue scraping – account for replies in T and P blogs
- [x] Complete financial aid checklist

----
# Menu

> What other things can I do today that are less important?
## Today

- [ ] Unpack and note ideas from Sara Walker talk
	- [ ] Make literature note, connect with Chiang’s “Truth of Fact, Truth of Fiction” story

## Future file

- [ ] Correspondences – email Rex, send photos to parents, respond to David’s emails
- [ ] Send thoughts on math opinion paper to Sara


---
# Notes

- Topic model of comments
	- Mallet code implementation – the only mathematically sound one?
	- Bayesian algorithm for generating each document
		- Each comment is a “document” – bag of words, distribution over topics
		- Topic defined by probability distribution over words
		- To generate a document (i.e., data generating process), topic → word → repeat for number of words in bag
	- Expectation maximization (EM) algorithm
	- Given generation process, Mallet returns maximum likelihood distributions
	- Algorithm wants distributions to be **sparse** (large for small number of things, e.g., one topic); $\alpha, \beta$ prior parameters can be set or hyper parametrized
		- Enforcing sparsity = more interpretable results in DL
		- Regression models – L1, L2, etc.
		- Blei Minmnow papers
		- Do things with Dirichlet dist. for params?
	- Practical things
		- Downcase everything and remove punctuation
		- Get a count for all words in data, remove top 100-200 words (check if there are any you don’t want to remove) – see French Rev. paper
	- Cognitive moves
	- Comments that are highly weighted for each comment?
	- How to select number of topics? – just try
		- Small number can drive intuition
		- Patterns across users?
		- Meta/spam? – maybe remove comments (would we be scientifically interested? E.g., semantic and cognitive topics, functional roles)
- Interesting subjects
	- Mathematical intuition
	- Examples – what are they used for?
	- Distributions of topics over time
- Next steps
	- Scrape comments and clean data
	- Make text file for all URLs

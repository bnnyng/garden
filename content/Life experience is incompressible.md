---
aliases:
  - constructivist
  - transmission model of education
tags:
  - permanent-note
  - topic-physics-complexity
  - seed
publish: "true"
date: 2024-06-05
lastmod: 2024-08-17T15:14:35-07:00
---
Author Ted Chiang presented the following claims during a talk for SFI’s [“Thought Experiments in Science and Fiction”](https://www.santafe.edu/events/thought-experiments-in-science-and-fiction) working group:
> - The learning gained by interacting with intelligent entities cannot be replicated by interacting with non-intelligent entities.
> - Life experience is incompressible. There are no shortcuts.

Chiang believes that [[Embodied cognition|embodied]] life experience precedes the evolution of intelligence. To evolve intelligent artificial organisms, then, we need an online world that supports full embodied physics. 

This argument is rooted in **constructivism**, which is a theory of education where students actively construct knowledge through experiences, thereby building a unique body of knowledge. In contrast, the **transmission model of education** prioritizes the role of a teacher who passes a standardized body of knowledge to students who passively absorb information. 

My thoughts: the difference between life experience and [[Memory|memory]] is that memory can be shared between people across both space and time—forms include culture, tradition, and Plato’s notion of a soul in [[plato-phaedo|Phaedo]]. Life experience includes the knowledge of how to act upon memory. 

As an aside, it seems that acquiring these shared memory examples is quite a constructivist process in practice—we learn things like cultural norms best by making highly informative mistakes. 

>[!question] Open questions
>- How might these ideas be implemented in AI design? Surely, many people are thinking about embodied learning, but maybe the directions do not feel as promising or lucrative. 
>- How do current approaches to training “intuitive physics” in AI compare?
>- What is the connection to the [[Interventionist theory of causation]]?
>- What is the [[Complexity is the study of teleonomic matter, after Krakauer|purpose]] of life experience that extends beyond shared [[Reality is mediated by our mental models|mental models]], such as culture?
>
>From [[@2022millhouse]]:
>- Is self-generated learning fully captured in the data gathered by infants about the world? That is, can AI agents learn from being trained on infant data without interacting with the world themselves?
>- Would an AI system trained on infant data have the same capacity for generalization as infants?

---
# Further reading

- Chiang, Ted (2010). “The Lifecycle of Software Objects”.
- Churchland, Patricia (2019). *Conscience: The Origins of Moral Intuition.*
- Grand, Steve (2000). *Creation: Life and How to Make It*.
- Ong, Walter J. (1982). *Orality and Literacy: The Technologizing of the Word.*